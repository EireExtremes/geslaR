---
title: "Dealing with the GESLA dataset in R"
output: rmarkdown::html_vignette
author: Fernando Mayer, Niamh Cahill
vignette: >
  %\VignetteIndexEntry{Dealing with the GESLA dataset in R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "fig-",
  fig.align = "center",
  out.width = "90%",
  cache = TRUE,
  cache.path = "intro-to-geslaR_cache/"
)
```

The **geslaR** package was designed to fetch the [GESLA][] dataset into
R, in full or subsets of it. There a few ways that this can be achieved:

- Downloading the entire dataset locally, then load it into R and work
  from there using the [Apache Arrow][] framework
  (`download_gesla()`)
- Querying the hosted dataset directly from R, specifying the desired
  subset (`query_gesla()`)
- Using the GESLA Shiny app (thereafter called only geslaR-app), to
  filter, visualise and possibly download subsets of the dataset
  (`run_gesla_app()`)
- Directly reading specific files from the full dataset, or reading
  files exported from the geslaR-app (`read_gesla()`)

In the sections below, we will discuss each of these possibilities.

## Loading the package

When you first load the **geslaR** package into an R session, two more
packages will automatically be loaded: **arrow** and **dplyr**.

```{r setup, cache=FALSE}
library(geslaR)
```

These two packages are strictly necessary, as it is the way to deal with
a huge dataset, like GESLA, without actually loading it in memory at
once. The full GESLA dataset have more than 1.7 billion lines, and is
nearly impossible to load it in R (or any other RAM memory language,
like e.g. Python) all at once. To avoid this problem, there are two
possibilities:

1. Load (smaller) subsets of the full dataset
2. Use an "in-memory" analytics framework

In the best case scenario, these two approaches can be used together for
maximum efficiency, and the **geslaR** package was designed for this
achievement.

Regardless the way GESLA data is loaded into R, the best way to deal
with it is using the [Apache Arrow][] framework. For a more detailed
explanation and examples, please see the
`vignette("intro-to-arrow")`.

## Downloading the full GESLA dataset

If you want to explore the full GESLA dataset, you can download it with
the `download_gesla()` function. The simplest way to use this function
is to call it like

```{r dir, include=FALSE, cache=FALSE}
if(!dir.exists("gesla_dataset")) download_gesla(ask = FALSE)
```

```{r dwl, eval=FALSE}
download_gesla()
```

This will create a directory called `gesla_dataset` in the current
working directory (as defined by `getwd()`) and download the full
dataset locally. This downlopad may take some time, as it depends on
internet connection, but it's necessary only once. Note that this full
dataset will need at least 7GB of (hard drive) storage, so make sure
this is feasible. However, once downloaded, you will have access to the
full dataset, and you will only need to do this once.

You will notice that the full dataset is composed by 5119 [Apache
Parquet][] files, ending in `.parquet`

```{r len}
## Number of downloaded files
length(list.files("gesla_dataset"))
## Check the first files
head(list.files("gesla_dataset"))
```

These files are the same originally distributed in the GESLA dataset, so
that each one refers to a site from where the data comes from. To load
this full dataset in R, use the `arrow::open_dataset()` function,
specifying the location of the `.parquet` files. Altough there are many
files, this function recognizes them as a single dataset, because they
all have the same structure (or "Schema").

```{r open}
## Open dataset
da <- open_dataset("gesla_dataset")
## Check the object
da
## Verify class
class(da)
```

Since this is an `ArrowObject` object, it will actually not load
the full dataset in memory (as it would if it was a standard R object,
such as a `tibble` or `data.frame`). Note that some basic informations,
such as `dim()` and `names()` can be retrieved simply with

```{r dim}
dim(da)
names(da)
```

However, any other manipulation of the dataset must be made using
**dplyr** verbs. For example, to count the number of observations by
country, one could use

```{r ctr}
da |>
    count(country) |>
    collect()
```

## Querying subsets directly into R

The `query_gesla()` function can be used to load subsets of the full
GESLA dataset into R. This function will connect to the GESLA dataset
hosted on an Amazon AWS S3 bucket, and will automatically filter the
required piece of data. Note that the query may take some time, as it
will depend on the size of the required subset and on internet
connection speed.

The selection is made by specifying one or more countries, years and
site names. The only mandatory argument is `country`, where it should be
a character vector of three-letter [ISO 3166-1
alpha-3](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3) code. If the
argument `year` is empty, then all available years for those countries
will be selected. The same accurs for the `site_name` argument.

For example, to select all the available data for Ireland (IRL), simply
use

```{r irl}
da <- query_gesla(country = "IRL")
da
dim(da)
names(da)
class(da)
```

This is also an `ArrowObject` object, and works the same way as any
other Arrow object type, i.e., it can be manipulated with **dplyr**
verbs. By the end of this section we will show some examples.

Many other queries can be made, for example,

```{r ex, eval=FALSE}
## Select one specific year
da <- query_gesla(country = "IRL", year = 2015)

## Multiple years
da <- query_gesla(country = "IRL", year = c(2015, 2017))
da <- query_gesla(country = "IRL", year = 2010:2017)
da <- query_gesla(country = "IRL", year = c(2010, 2012, 2015))

## Multiple countries
da <- query_gesla(country = c("IRL", "ATA"), year = 2015)
da <- query_gesla(country = c("IRL", "ATA"), year = 2010:2017)
```

As one last example, we may be interested in data only for the site
`Dublin_Port` in Ireland, and for the years 2015 and 2017. This query
would be done as follows

```{r dub}
da <- query_gesla(country = "IRL", year = c(2015, 2017),
    site_name = "Dublin_Port")
```

Now we could explore this subset using **dplyr** verbs as usual

```{r expl}
## Verifying number of observations per year
da |>
    count(year) |>
    collect()

## Calculating summary statistics per year
da |>
    group_by(year) |>
    summarise(
        min = min(sea_level),
        mean = mean(sea_level),
        max = max(sea_level)) |>
    collect()
```

Note the use of the [dplyr::collect()] function at the end of each call.
This is necessary to convert the final result (which is processed by
Arrow) to a common R object (usually a `tibble` or similar).

As stated before, the queries made by `query_gesla()` may take some
time to process. To avoid repeating this query in every new session, you
can save this object in a file locally, so it will be available
instantly the next time you may need it. To achieve this, you can use
the `write_gesla()` function

```{r, eval=FALSE}
write_gesla(da)
```

In this case, this call will create a file named `gesla-data.parquet`,
and it will be ready for reading at any time, without the need for
querying again. At any time, just use

```{r, eval=FALSE}
da <- read_gesla("gesla-data.parquet")
```

to make it available again.

Please, do not try to save this object as a standard R file, such as
`.rds` or `.rda`, as using `saveRDS` or `save()` for example. In this
case the resulting saved object will not be the same as the original
object, as an `ArrowObject` object is not a standard R object (it
actually is just a pointer to an Arrow style opbject).

The `query_gesla()` function also has two more arguments. The `use_flag
= 1` means that only the data revised by the GESLA team and usefull for
analysis must be used. Please see the [GESLA format][] page for more
information. The other argument, `as_data_frame = FALSE` specifies if
the resulting object should be an `ArrowObject` (the default) or a
`data.frame`. We highly recommend to keep this default option, as the
resulting `data.frame` can be larger-than-memory, resukting in a memory
overflow or even an R session crash. Keeping the object as an
`ArrowObject` will always guarantee that the resulting query will be
made available. In any case, an `ArrowObject` can always be converted to
a `data.frame`, if that is desired, without the need to repeat the query
with `as_data_frame = TRUE`. For example, the object `da` created above
(which is an `ArrowObject`) may be converted to a `data.frame` with

```{r conv}
class(da)
db <- da |>
    collect()
class(db)
```

## Using the GESLA Shiny app


## Reading GESLA data files


[GESLA]: https://gesla787883612.wordpress.com
[Apache Arrow]: https://arrow.apache.org
[GESLA format]: https://gesla787883612.wordpress.com/format/
